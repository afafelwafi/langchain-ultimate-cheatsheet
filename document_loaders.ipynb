{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a77257-2c87-4517-a8ac-911badc918ca",
   "metadata": {},
   "source": [
    "# Document Loaders\n",
    "\n",
    "Document loaders in LangChain are responsible for reading and parsing various types of documents into a format that can be used for further processing (such as indexing or querying). These loaders are essential for turning unstructured data (e.g., PDFs, websites, text files) into structured representations that LLMs (Large Language Models) or other systems can process effectively.\n",
    "\n",
    "#### Common Document Loaders in LangChain:\n",
    "- TextLoader: Loads plain text files and returns the contents as a string.\n",
    "- PDFLoader: Loads and extracts text from PDF files.\n",
    "- CSVLoader: Reads CSV files and parses the rows into a list of dictionaries or other suitable structures.\n",
    "- WebBaseLoader: Loads content from web pages via URLs, extracting text from HTML.\n",
    "- DocxLoader: Loads DOCX (Word) files and extracts the text from them.\n",
    "- JSONLoader: Loads JSON files and parses them into Python dictionaries.\n",
    "- NotebookLoader: Loads Jupyter Notebooks and extracts text from them.\n",
    "- HTMLLoader: Loads HTML files, extracting readable text while ignoring HTML tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f923ba-6a50-4fda-91cb-53a39f62e247",
   "metadata": {},
   "source": [
    "## Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb78453-449d-44be-805f-1593286f0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING FILE\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"files/data.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05660c05-d7a8-4033-93e7-0f23b12b4ba6",
   "metadata": {},
   "source": [
    "- Handling directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "490f9474-38a2-46c9-b27e-76cb42d7072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'files/data_2.txt.txt'}, page_content='TESTING FILE'), Document(metadata={'source': 'files/data.txt'}, page_content='TESTING FILE')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\n",
    "    \"./files/\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "documents = directory_loader.load()\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dc76b-940b-4029-be82-368199e37d82",
   "metadata": {},
   "source": [
    "## CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704aa4fd-4358-448c-b8c1-758d0a6501bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'files/data.csv', 'row': 0}, page_content='Years: 2011\\nHistorical Data: 11.1%\\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 1}, page_content='Years: 2012\\nHistorical Data: 11.5%\\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 2}, page_content='Years: 2013\\nHistorical Data: 11.0%\\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 3}, page_content='Years: 2014\\nHistorical Data: 11.2%\\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 4}, page_content='Years: 2015\\nHistorical Data: \\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 5}, page_content='Years: 2016\\nHistorical Data: \\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 6}, page_content='Years: 2017\\nHistorical Data: \\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 7}, page_content='Years: 2018\\nHistorical Data: \\nTarget: '),\n",
       " Document(metadata={'source': 'files/data.csv', 'row': 8}, page_content='Years: 2019\\nHistorical Data: \\nTarget: 10.1%')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "csv_loader = CSVLoader(\"files/data.csv\")\n",
    "documents = csv_loader.load()\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca4353-bfc2-4a05-afaf-f7943bb124bd",
   "metadata": {},
   "source": [
    "## PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8365ee0-b081-445f-9081-56f0629b4b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-24T00:24:36+00:00', 'author': '', 'keywords': '', 'moddate': '2022-06-24T00:24:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'files/data.pdf', 'total_pages': 34, 'page': 0, 'page_label': '1'}, page_content='FlashAttention: Fast and Memory-Eﬃcient Exact Attention\\nwith IO-Awareness\\nTri Daoy, Daniel Y. Fuy, Stefano Ermony, Atri Rudraz, and Christopher Réy\\nyDepartment of Computer Science, Stanford University\\nzDepartment of Computer Science and Engineering, University at Buﬀalo, SUNY\\n{trid,danfu}@cs.stanford.edu, ermon@stanford.edu, atri@buffalo.edu,\\nchrismre@cs.stanford.edu\\nJune 24, 2022\\nAbstract\\nTransformers are slow and memory-hungry on long sequences, since the time and memory complexity\\nof self-attention are quadratic in sequence length. Approximate attention methods have attempted\\nto address this problem by trading oﬀ model quality to reduce the compute complexity, but often do\\nnot achieve wall-clock speedup. We argue that a missing principle is making attention algorithmsIO-\\naware—accounting for reads and writes between levels of GPU memory. We proposeFlashAttention,\\nan IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes\\nbetween GPU high bandwidth memory (HBM) and GPU on-chip SRAM. We analyze the IO complexity\\nof FlashAttention, showing that it requires fewer HBM accesses than standard attention, and is\\noptimal for a range of SRAM sizes. We also extendFlashAttention to block-sparse attention, yielding\\nan approximate attention algorithm that is faster than any existing approximate attention method.\\nFlashAttention trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup\\non BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3\\x02speedup on\\nGPT-2 (seq. length 1K), and 2.4\\x02speedup on long-range arena (seq. length 1K-4K).FlashAttention\\nand block-sparseFlashAttention enable longer context in Transformers, yielding higher quality models\\n(0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classiﬁcation) and entirely new\\ncapabilities: the ﬁrst Transformers to achieve better-than-chance performance on the Path-X challenge\\n(seq. length 16K, 61.4% accuracy) and Path-256 (seq. length 64K, 63.1% accuracy).\\n1 Introduction\\nTransformer models [82] have emerged as the most widely used architecture in applications such as natural\\nlanguage processing and image classiﬁcation. Transformers have grown larger [5] and deeper [83], but\\nequipping them with longer context remains diﬃcult [80], since the self-attention module at their heart\\nhas time and memory complexity quadratic in sequence length. An important question is whether making\\nattention faster and more memory-eﬃcient can help Transformer models address their runtime and memory\\nchallenges for long sequences.\\nMany approximate attention methods have aimed to reduce the compute and memory requirements of\\nattention. These methods range from sparse-approximation [51, 74] to low-rank approximation [12, 50, 84],\\nand their combinations [3, 9, 92]. Although these methods reduce the compute requirements to linear or\\nnear-linear in sequence length, many of them do not display wall-clock speedup against standard attention\\nand have not gained wide adoption. One main reason is that they focus on FLOP reduction (which may not\\ncorrelate with wall-clock speed) and tend to ignore overheads from memory access (IO).\\nIn this paper, we argue that a missing principle is making attention algorithmsIO-aware [1]—that is,\\ncarefully accounting for reads and writes to diﬀerent levels of fast and slow memory (e.g., between fast GPU\\non-chip SRAM and relatively slow GPU high bandwidth memory, or HBM [45], Figure 1 left). On modern\\n1\\narXiv:2205.14135v2  [cs.LG]  23 Jun 2022'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2022-06-24T00:24:36+00:00', 'author': '', 'keywords': '', 'moddate': '2022-06-24T00:24:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'files/data.pdf', 'total_pages': 34, 'page': 1, 'page_label': '2'}, page_content='FlashAttention\\nMemory Hierarchy with\\nBandwidth & Memory Size\\nAttention on GPT-2\\nFlashAttentionPyTorch\\nTime (ms)\\nMatmul\\nMask\\nSoftmax\\nDropout\\nMatmul\\nFused\\nKernel\\nQ: N x d V: N X d\\nKT: d x N\\nQKT: N x N\\nsm(QKT)V: N x d\\nOuter Loop\\nCopy Block to SRAM\\nCopy\\nOuter Loop\\nCopy\\nInner Loop\\nCompute Block\\non SRAM\\nOutput to HBM\\nInner Loop\\nInner Loop\\nOuter Loop\\nGPU\\nSRAM\\nGPU\\nHBM\\nMain Memory\\n(CPU DRAM)\\nSRAM: 19 TB/s (20 MB)\\nHBM: 1.5 TB/s (40 GB)\\nDRAM: 12.8 GB/s\\n                (>1 TB)\\n0\\n5\\n10\\n15\\nFigure 1: Left: FlashAttention uses tiling to prevent materialization of the large𝑁\\x02𝑁 attention matrix\\n(dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows),FlashAttention loops through\\nblocks of theK and V matrices and loads them to fast on-chip SRAM. In each block,FlashAttention\\nloops over blocks ofQ matrix (blue arrows), loading them to SRAM, and writing the output of the attention\\ncomputation back to HBM.Right: Speedup over the PyTorch implementation of attention on GPT-2.\\nFlashAttention does not read and write the large𝑁\\x02𝑁 attention matrix to HBM, resulting in an 7.6\\x02\\nspeedup on the attention computation.\\nGPUs, compute speed has out-paced memory speed [61, 62, 63], and most operations in Transformers are\\nbottlenecked by memory accesses [43]. IO-aware algorithms have been critical for similar memory-bound\\noperations, when reading and writing data can account for a large portion of the runtime—such as database\\njoins [71], image processing [70], numerical linear algebra [4], and more [40, 85]. However, common Python\\ninterfaces to deep learning such as PyTorch and Tensorﬂow do not allow ﬁne-grained control of memory\\naccess.\\nWe proposeFlashAttention, a new attention algorithm that computes exact attention with far fewer\\nmemory accesses. Our main goal is to avoid reading and writing the attention matrix to and from HBM.\\nThis requires (i) computing the softmax reduction without access to the whole input (ii) not storing the large\\nintermediate attention matrix for the backward pass. We apply two well-established techniques to address\\nthese challenges. (i) We restructure the attention computation to split the input into blocks and make several\\npasses over input blocks, thus incrementally performing the softmax reduction (also known astiling). (ii) We\\nstore the softmax normalization factor from the forward pass to quicklyrecompute attention on-chip in the\\nbackward pass, which is faster than the standard approach of reading the intermediate attention matrix from\\nHBM. We implementFlashAttention in CUDA to achieve ﬁne-grained control over memory access and\\nfuse all the attention operations into one GPU kernel. Even with the increased FLOPs due to recomputation,\\nour algorithm bothruns faster(up to 7.6x on GPT-2 [67], Figure 1 right) anduses less memory—linear\\nin sequence length—than standard attention, thanks to the massively reduced amount of HBM access.\\nWe analyze the IO complexity [1] of FlashAttention, proving that it requires𝑂¹𝑁2𝑑2𝑀\\x001ºHBM\\naccesses where𝑑 is the head dimension and𝑀 is the size of SRAM, as compared toΩ¹𝑁𝑑 ¸𝑁2ºof standard\\nattention. For typical values of𝑑 and 𝑀, FlashAttention requires many times fewer HBM accesses\\ncompared to standard attention (up to 9\\x02fewer, as shown in Fig. 2). Moreover, we provide a lower bound,\\nshowing that no exact attention algorithm can asymptotically improve on the number of HBM accesses over\\nall SRAM sizes.\\nWe also show thatFlashAttention can serve as a useful primitive for realizing the potential of\\napproximate attention algorithms by overcoming their issues with memory access overhead. As a proof of\\nconcept, we implement block-sparseFlashAttention, a sparse attention algorithm that is 2-4\\x02faster than\\neven FlashAttention, scaling up to sequence length of 64k. We prove that block-sparseFlashAttention\\nhas better IO complexity thanFlashAttention by a factor proportional to the sparsity ratio. We discuss')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"files/data.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "pages[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe022dd9-4278-40c1-bc7f-3aef25b35863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using UnstructuredPDFLoader (requires unstructured package)\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f47af-ecc0-4b22-9c07-2bfc825247e9",
   "metadata": {},
   "source": [
    "## Web Pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9383ab88-546d-4433-ba00-1e5151428f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://example.com/page1', 'title': 'Example Domain', 'language': 'No language found.'}, page_content='\\n\\n\\nExample Domain\\n\\n\\n\\n\\n\\n\\n\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://example.com/page2', 'title': 'Example Domain', 'language': 'No language found.'}, page_content='\\n\\n\\nExample Domain\\n\\n\\n\\n\\n\\n\\n\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://example.com\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Loading multiple URLs\n",
    "urls = [\n",
    "    \"https://example.com/page1\",\n",
    "    \"https://example.com/page2\",\n",
    "]\n",
    "multi_loader = WebBaseLoader(urls)\n",
    "documents = multi_loader.load()\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e297e9-ab5c-4ef6-8f36-9617d6365193",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9fd9348-0441-4f40-b5aa-b3060405e3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Name: AC/DC'),\n",
       " Document(metadata={}, page_content='Name: Accept'),\n",
       " Document(metadata={}, page_content='Name: Aerosmith'),\n",
       " Document(metadata={}, page_content='Name: Alanis Morissette'),\n",
       " Document(metadata={}, page_content='Name: Alice In Chains'),\n",
       " Document(metadata={}, page_content='Name: Antônio Carlos Jobim'),\n",
       " Document(metadata={}, page_content='Name: Apocalyptica'),\n",
       " Document(metadata={}, page_content='Name: Audioslave'),\n",
       " Document(metadata={}, page_content='Name: Azymuth'),\n",
       " Document(metadata={}, page_content='Name: A Cor Do Som'),\n",
       " Document(metadata={}, page_content='Name: Aquaman'),\n",
       " Document(metadata={}, page_content=\"Name: Aerosmith & Sierra Leone's Refugee Allstars\"),\n",
       " Document(metadata={}, page_content='Name: Avril Lavigne'),\n",
       " Document(metadata={}, page_content='Name: Aisha Duo'),\n",
       " Document(metadata={}, page_content='Name: Aaron Goldberg'),\n",
       " Document(metadata={}, page_content='Name: Alberto Turco & Nova Schola Gregoriana'),\n",
       " Document(metadata={}, page_content='Name: Anne-Sophie Mutter, Herbert Von Karajan & Wiener Philharmoniker'),\n",
       " Document(metadata={}, page_content='Name: Academy of St. Martin in the Fields & Sir Neville Marriner'),\n",
       " Document(metadata={}, page_content='Name: Academy of St. Martin in the Fields Chamber Ensemble & Sir Neville Marriner'),\n",
       " Document(metadata={}, page_content='Name: Academy of St. Martin in the Fields, John Birch, Sir Neville Marriner & Sylvia McNair'),\n",
       " Document(metadata={}, page_content='Name: Aaron Copland & London Symphony Orchestra'),\n",
       " Document(metadata={}, page_content='Name: Academy of St. Martin in the Fields, Sir Neville Marriner & William Bennett'),\n",
       " Document(metadata={}, page_content='Name: Antal Doráti & London Symphony Orchestra'),\n",
       " Document(metadata={}, page_content='Name: Amy Winehouse'),\n",
       " Document(metadata={}, page_content='Name: Academy of St. Martin in the Fields, Sir Neville Marriner & Thurston Dart'),\n",
       " Document(metadata={}, page_content='Name: Adrian Leaper & Doreen de Feis')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "import requests\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "# db from https://github.com/lerocha/chinook-database\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    connection.executescript(sql_script)\n",
    "    return create_engine(\n",
    "        \"sqlite://\",\n",
    "        creator=lambda: connection,\n",
    "        poolclass=StaticPool,\n",
    "        connect_args={\"check_same_thread\": False},\n",
    "    )\n",
    "\n",
    "\n",
    "engine = get_engine_for_chinook_db()\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "\n",
    "# Define your query string\n",
    "query = \"SELECT Name from Artist WHERE Name like 'A%'\"\n",
    "loader = SQLDatabaseLoader(db=db, query=query)\n",
    "\n",
    "documents = loader.load()\n",
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66bfca7-36f9-4d86-bb4b-635f4ba704a6",
   "metadata": {},
   "source": [
    "# Vector Stores\n",
    " vector stores are data structures used to store and retrieve embeddings (vector representations of data). They allow efficient similarity search by converting documents, queries, or other text into vectors and then finding the closest matching vectors based on a distance metric (e.g., cosine similarity). LangChain integrates with various vector store backends like Pinecone, ChromaDb, FAISS, and Weaviate to perform these operations. We will explore some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68474d4c-36f2-4f2b-89f5-acb9453323eb",
   "metadata": {},
   "source": [
    "- Setup of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca52dde-5c63-4cf1-aedf-09f9e6ed3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Section to change according to your choice of APIs you have access to ===============\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "text = \"Write a short poem about programming.\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b5ae1-c063-4b5e-aa0e-dec038cbb358",
   "metadata": {},
   "source": [
    "- Setup of Documents/Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b74d47c-de80-477a-abb4-35f21d2bb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water.\",\n",
    "        metadata={\n",
    "            \"source\": \"Biology Textbook\",\n",
    "            \"author\": \"Dr. Alice Green\",\n",
    "            \"date\": \"2021-03-15\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Quantum entanglement is a physical phenomenon that occurs when pairs or groups of particles are generated such that the quantum state of each particle cannot be described independently of the others.\",\n",
    "        metadata={\n",
    "            \"source\": \"Physics Journal\",\n",
    "            \"author\": \"Dr. John Quantum\",\n",
    "            \"date\": \"2022-06-01\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The theory of plate tectonics describes the large-scale motion of Earth's lithosphere and explains phenomena such as earthquakes and mountain formation.\",\n",
    "        metadata={\n",
    "            \"source\": \"Geology Magazine\",\n",
    "            \"author\": \"Dr. Emily Stone\",\n",
    "            \"date\": \"2020-11-23\"\n",
    "        }\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"CRISPR is a powerful tool for editing genomes, allowing researchers to easily alter DNA sequences and modify gene function.\",\n",
    "        metadata={\n",
    "            \"source\": \"Genetics Weekly\",\n",
    "            \"author\": \"Dr. Rachel Gene\",\n",
    "            \"date\": \"2023-01-10\"\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "texts = [\"Text 1\", \"Text 2\", \"Text 3\", \"Text 4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99997c6f-2f39-4ecf-9503-d1843f12ce4f",
   "metadata": {},
   "source": [
    "## FAISS\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is an **open-source** library developed by Facebook AI Research designed to efficiently search for similar vectors in large datasets. It provides tools for nearest neighbor search, clustering, and vector quantization, making it ideal for handling high-dimensional data like word embeddings or other types of vectors\n",
    "FAISS indexes are typically stored in in-memory by default, but they can also be persisted to disk for later use.\n",
    "- In-Memory: When you create an index, FAISS keeps it in memory. This allows fast querying but can be limited by the amount of available system memory, especially for large datasets.\n",
    "- On Disk: FAISS provides functionality to save and load indexes from disk. This can be useful for large datasets or when you need to persist the index for future use. You can save the index to a file and load it again later without needing to recompute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c922d0e-48ae-4487-a7f7-a14449e05f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='6a26b38b-0096-4b03-ae20-583cac160a6a', metadata={'source': 'Genetics Weekly', 'author': 'Dr. Rachel Gene', 'date': '2023-01-10'}, page_content='CRISPR is a powerful tool for editing genomes, allowing researchers to easily alter DNA sequences and modify gene function.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Create from texts\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Search\n",
    "docs = vectorstore.similarity_search(\"what can be used for editing genomes\", k=1)\n",
    "print(docs)\n",
    "\n",
    "# Save and load\n",
    "vectorstore.save_local(\"db/faiss_index\")\n",
    "loaded_vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd5bee-4eb3-409d-a289-ea1f39c271c3",
   "metadata": {},
   "source": [
    "## Chroma\n",
    "Chroma is an **open-source** vector database used for storing and querying high-dimensional embeddings. It stores indexes and metadata on disk by default, using an **SQLite backend** for persistent storage. The index location can be customized by specifying a directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f70161f-1ea3-47d8-ad5c-027de2f23cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create from documents\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./db/chroma_db\"\n",
    ")\n",
    "\n",
    "\n",
    "# Load existing DB\n",
    "loaded_vectorstore = Chroma(\n",
    "    persist_directory=\"./db/chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Search with metadata filtering\n",
    "docs = loaded_vectorstore.similarity_search(\n",
    "    \"what do we use to edit genomes\",\n",
    "    k=1,\n",
    "    filter={\"source\": \"news\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c62bac-377d-4df7-8e7f-9f9d532ba94c",
   "metadata": {},
   "source": [
    "## Pinecone\n",
    "Pinecone is a **managed** vector database used for storing and retrieving high-dimensional vectors (embeddings). When using Pinecone in LangChain, embeddings are stored in a Pinecone index, which is hosted and managed by Pinecone's infrastructure in the **cloud**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e3adb27-e138-40fc-bb9c-7d4778396579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the embedding for the text\n",
    "text = \"test\"\n",
    "embedding = embeddings.embed_query(text)\n",
    "# Get the dimension (length of the embedding)\n",
    "embedding_dimension = len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6eef6b7e-6143-4b79-b7f4-004e086d8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone()\n",
    "# Create or connect to an index\n",
    "index_name = \"langchain-demo\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dimension,  # OpenAI embeddings dimensions\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",  # or \"gcp\"\n",
    "            region=\"us-east-1\"  # or your desired region\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c464ed4-39db-4878-9b8f-d9d05336e274",
   "metadata": {},
   "source": [
    "![title](files/pinecone_index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "431db48d-4406-4ca0-8455-8c6b5f6fb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='ca01e0df-51d7-4a98-81ff-0bdaf26237aa', metadata={}, page_content='Text 1')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "index_name = \"langchain-demo\"\n",
    "\n",
    "# Create vectorstore\n",
    "vectorstore = PineconeVectorStore.from_texts( # you can also use texts directly instead of documents\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    ")\n",
    "\n",
    "# Search\n",
    "docs = vectorstore.similarity_search(\"query text\", k=3)\n",
    "print(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

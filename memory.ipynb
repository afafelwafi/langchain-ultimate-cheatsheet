{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d54341e-f32c-4c4f-aba4-8f3a19b21dff",
   "metadata": {},
   "source": [
    "# Conversation Memory\n",
    "\n",
    "onversation Memory refers to the mechanism that allows an LLM-powered app (like a chatbot or agent) to remember previous interactions in a session. It’s what lets a conversation feel coherent, contextual, and “alive.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789fa3a-50d6-4a4c-b734-8dcb29739ecd",
   "metadata": {},
   "source": [
    "- Prepare a Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b32cbcce-974c-4521-a4df-096d85a2ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74069253-2868-46e6-8da8-14068dfefd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a type of computation that utilizes the principles of quantum mechanics to perform operations on data. Unlike classical computers that use bits (0s and 1s) to represent and manipulate data, quantum computers use quantum bits, or qubits.\n",
      "\n",
      "A qubit can exist in multiple states simultaneously, thanks to a property known as superposition. This means that a qubit can be both 0 and 1 at the same time - a concept known as quantum superposition.\n",
      "\n",
      "Another key principle in quantum computing is entanglement. This occurs when pairs or groups of qubits become interconnected and the state of one qubit can instantly affect the state of the others, no matter the physical distance between them. This phenomenon allows quantum computers to perform certain calculations much faster than classical computers.\n",
      "\n",
      "Quantum computers also utilize a third state known as the quantum oscillator, or quantum phase, which can further enhance their computational power.\n",
      "\n",
      "These unique properties of qubits enable quantum computers to solve problems that are difficult, if not impossible, for classical computers to solve efficiently. This includes optimization, simulation, cryptography, and machine learning problems. However, creating and maintaining stable qubits and keeping them linked through entanglement remains a significant challenge, as does writing useful algorithms for these machines.\n",
      "\n",
      "Quantum computing has exciting potential to revolutionize many fields, from drug discovery to artificial intelligence, although it's still in its early stages of development and practical application.\n"
     ]
    }
   ],
   "source": [
    "# =================== Section to change according to your choice of APIs you have access to===============\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# llm\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    task=\"text-generation\",  # Ensure the correct task type\n",
    "    temperature=0.5,\n",
    "    max_new_tokens=128  # Adjust max_new_tokens for generation\n",
    ")\n",
    "\n",
    "# Set up ChatHuggingFace\n",
    "chatllm = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# Test with a prompt\n",
    "try:\n",
    "    response = chatllm.invoke(\"Explain the concept of quantum computing.\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a012f-069d-4048-8928-c05975719060",
   "metadata": {},
   "source": [
    "## Simple conversation memory\n",
    "ConversationBufferMemory is a memory class in LangChain that stores and remembers the full chat history between the user and the LLM during a conversation [ConversationChain]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70b4a388-8104-49ee-be0c-3f58546a0452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on our previous conversation, your name is Alice. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chatllm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "try:\n",
    "    conversation.invoke(\"Hi, my name is Alice.\")\n",
    "    response = conversation.invoke(\"What's my name?\")  # Should remember \"Alice\"\n",
    "    print(response['response'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73619dc4-c7a8-41d4-ace7-e54a2027dd5b",
   "metadata": {},
   "source": [
    "- Memory with specific key names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f679f345-a29a-4335-92e6-ac92e292a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56654e8c-36a2-4485-9ad0-88ecbb05b39c",
   "metadata": {},
   "source": [
    "- ConversationBufferWindowMemory (keeps only last k interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70b2f46e-6923-4ef4-98b3-28108d1850dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "window_memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edc75a-4e14-4703-966f-c9ce83a47381",
   "metadata": {},
   "source": [
    "- ConversationSummaryMemory (summarizes older context)\n",
    " \n",
    "  Using LLM for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73af012f-c79d-4231-877d-1912c5cd4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "summary_memory = ConversationSummaryMemory(llm=chatllm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84d158-c0e0-4b29-a026-76c8bfeb97f7",
   "metadata": {},
   "source": [
    "## Vector Store Memory\n",
    "\n",
    "Vector Store Memory is a type of memory in LangChain that stores past conversation chunks (or context) in a vector store — such as FAISS, Chroma, or Weaviate — and retrieves relevant messages based on semantic similarity, rather than just time-based order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9dd026f6-062c-4a95-9347-a523cbc0049c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'User likes red and blue colors'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# Create vector store\n",
    "vector_store = FAISS.from_texts([\"User likes red and blue colors\"], embeddings)\n",
    "retriever = vector_store.as_retriever(search_kwargs=dict(k=1))\n",
    "\n",
    "# Create memory\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# Save information to memory\n",
    "memory.save_context(\n",
    "    {\"input\": \"My favorite colors are red and blue\"},\n",
    "    {\"output\": \"I'll remember that you like red and blue.\"}\n",
    ")\n",
    "\n",
    "# Retrieve from memory\n",
    "memory.load_memory_variables({\"prompt\": \"What colors do I like?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e640479-7fe4-49e5-ad1a-f188c0e09f00",
   "metadata": {},
   "source": [
    "# Text splitters\n",
    "\n",
    "In LangChain, text splitters are tools used to divide large documents into smaller, more manageable chunks of text. This is particularly useful when working with large documents that cannot be processed in a single pass due to model input size limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9685215b-2f07-4141-9c1f-d3abea0ce012",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"\"\"Large Language Models (LLMs) are a type of artificial intelligence model trained on vast amounts of textual data.\\n\n",
    "They use deep learning, specifically transformer architectures, to understand, generate, and manipulate human language in a meaningful way.\\n\n",
    "Some well-known LLMs include OpenAI's GPT series, Google's PaLM, Meta's LLaMA, and Anthropic's Claude.\\n\n",
    "\n",
    "### Core Concepts of LLMs:\\n\n",
    "1. **Tokenization**: Breaking text into smaller units called tokens.\\n\n",
    "2. **Transformer Architecture**: A neural network structure that uses self-attention to weigh the importance of each word.\\n\n",
    "3. **Pretraining and Finetuning**: Models are pretrained on large corpora and then optionally finetuned on specific tasks.\\n\n",
    "\n",
    "---\\n\n",
    "\n",
    "### Applications of LLMs:\\n\n",
    "- Text Generation (e.g., writing stories, articles)\\n\n",
    "- Summarization\\n\n",
    "- Translation\\n\n",
    "- Sentiment Analysis\\n\n",
    "- Code generation\\n\n",
    "- Question Answering\\n\n",
    "\n",
    "***\\n\n",
    "\n",
    "### Challenges with LLMs:\\n\n",
    "- **Bias**: LLMs can reflect and even amplify societal biases found in their training data.\\n\n",
    "- **Hallucination**: They might generate confident but incorrect or fabricated information.\\n\n",
    "- **Resource Intensity**: Training and running these models require significant computational power.\\n\n",
    "\n",
    "---\\n\n",
    "\n",
    "### Recent Trends:\\n\n",
    "- **Retrieval-Augmented Generation (RAG)**: Combines LLMs with information retrieval systems.\\n\n",
    "- **Multimodal Models**: Extend LLMs to understand not just text but images, audio, and video.\\n\n",
    "- **Agents and Tool Use**: LLMs that interact with tools or APIs to perform tasks (e.g., browsing, math solving).\\n\n",
    "\n",
    "***\\n\n",
    "\n",
    "In summary, LLMs have revolutionized natural language processing, enabling machines to interact with humans in powerful new ways.\\n\n",
    "As research continues, we expect LLMs to become more capable, efficient, and aligned with human values.\\n\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa530d6-2564-4ec7-9d77-6e4da7cbf9f2",
   "metadata": {},
   "source": [
    "## Simple character text splitter\n",
    "This splitter divides text into chunks based on a fixed number of characters. It's simple and effective when you need to break a document into chunks of a specific size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0989dbbc-2c1a-43aa-bb36-e82b86aa9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0 has 1785 character\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Simple character text splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "texts = text_splitter.split_text(long_text)\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"text {i} has {len(text)} character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c774898-5573-4eb2-9834-4660ddc2fa51",
   "metadata": {},
   "source": [
    "## Recursive character text splitter (preferred)\n",
    "This splitter is more sophisticated. It recursively splits text by both characters and logical boundaries (like paragraphs or sentences), trying to keep the chunks at an optimal size while preserving context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7599137-4513-4c3d-a14d-57a825987e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0 has 921 character\n",
      "text 1 has 939 character\n",
      "text 2 has 240 character\n"
     ]
    }
   ],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "texts = recursive_splitter.split_text(long_text)\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"text {i} has {len(text)} character\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009a0da-08c4-4c1a-b50d-12ba316c8293",
   "metadata": {},
   "source": [
    "## Token-based splitter\n",
    "his splitter divides text based on the number of tokens rather than characters. It is especially useful for models that work on tokenized input, where the number of tokens is a better measure of input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "235d3e26-0985-49af-8588-14602dc20993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 437\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "# Load GPT-2 tokenizer (you can use other models like GPT-3)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.encode(long_text)\n",
    "\n",
    "# Check how many tokens\n",
    "print(f\"Total tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a18f088f-5f71-402d-9b57-c7f29c3a5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 0 has 811 character\n",
      "text 1 has 772 character\n",
      "text 2 has 236 character\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=5\n",
    ")\n",
    "texts = token_splitter.split_text(long_text)\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"text {i} has {len(text)} character\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

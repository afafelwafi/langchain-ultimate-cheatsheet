{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411a2217-2913-4636-a65f-77a8c27e8b60",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "A prompt is the input text or instruction given to a language model to generate a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3853c-5a01-4036-bb09-ede1d129f2b3",
   "metadata": {},
   "source": [
    "- Setup: \n",
    "This is the setup to create a ChatLLM model using Langchain, please refer to model and integration to see the other possible options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d0dc577-577b-44c2-9df7-e185a1a0be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Section to change according to your choice of APIs you have access to===============\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6200a3c-c6b5-4ad6-abab-ba727f7214fe",
   "metadata": {},
   "source": [
    "## PromptTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84280e-08ad-436f-b340-6d7d8bc6a738",
   "metadata": {},
   "source": [
    "- Basic prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24940041-294f-419d-a690-0c6b24fee732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about programming.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "template = \"Tell me a {adjective} joke about {subject}.\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"subject\"],  # can be commented\n",
    "    template=template\n",
    ")\n",
    "\n",
    "formatted_prompt = prompt.format(adjective=\"funny\", subject=\"programming\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6531b8-624e-42a4-85b9-75867c778239",
   "metadata": {},
   "source": [
    "- Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d9cd7e-fa24-4c4d-bcfd-567e639debb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm going to give you some examples of analyzing sentiment:\n",
      "\n",
      "Text: I love this product!\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: This is the worst experience ever.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: I am feeling blue today\n",
      "Sentiment:\n"
     ]
    }
   ],
   "source": [
    "few_shot_template = \"\"\"\n",
    "I'm going to give you some examples of analyzing sentiment:\n",
    "\n",
    "Text: I love this product!\n",
    "Sentiment: Positive\n",
    "\n",
    "Text: This is the worst experience ever.\n",
    "Sentiment: Negative\n",
    "\n",
    "Text: {input_text}\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "few_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"input_text\"], # can be commented\n",
    "    template=few_shot_template\n",
    ")\n",
    "\n",
    "formatted_few_shot_prompt = few_shot_prompt.format(input_text=\"I am feeling blue today\")\n",
    "print(formatted_few_shot_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff3240-7d3d-4220-85ec-aa6b01778385",
   "metadata": {},
   "source": [
    "## Chat Prompt Templates\n",
    "\n",
    "PromptTemplate: Used for standard, non-chat-based prompts where you pass a single string of text.\n",
    "\n",
    "ChatPromptTemplate: Specifically for chat-based models, where you manage multiple message types (like user and assistant) in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b0a971f-d370-42e4-9da5-d375e067ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI assistant specialized in data science.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you help me with: How do I analyze time series data??', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant specialized in {topic}.\"),\n",
    "    (\"human\", \"Can you help me with: {question}?\")\n",
    "])\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    topic=\"data science\",\n",
    "    question=\"How do I analyze time series data?\"\n",
    ")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa158fa1-d179-49c3-a01b-cb307029fd6e",
   "metadata": {},
   "source": [
    "- Using LangChain Expression Language (LCEL)\n",
    "\n",
    "LangChain Expression Language (LCEL) is a specialized language in LangChain that allows you to define and execute dynamic expressions within prompts, enabling flexible and customized interactions with language models. It helps in interpolating variables and processing logic within templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d859d89-1aa5-430c-a64b-ddfaeb82d62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write a poem about {topic}\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "try:\n",
    "    response = chain.invoke({\"topic\": \"autumn leaves\"})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5e100-463a-48ca-8001-fff0d13640fd",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "In LangChain, an Output Parser is a component that takes the raw output from an LLM (usually a string) and converts it into a structured formatâ€”such as a Python dictionary, list, Pydantic model, or even LangChain-specific objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5bad60f-c0cd-49c4-9ca1-7c813189f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Define Movie and MovieList Pydantic models\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(description=\"Title of the movie\")\n",
    "    director: str = Field(description=\"Director of the movie\")\n",
    "    year: int = Field(description=\"Year the movie was released\")\n",
    "\n",
    "class MovieList(BaseModel):\n",
    "    movies: List[Movie] = Field(description=\"List of movies\")\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate {number} movies about {topic}. List their titles, directors, and release years.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create the parser\n",
    "parser = PydanticOutputParser(pydantic_object=MovieList)\n",
    "\n",
    "# Create the chain with the model and parser\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Invoke the chain to get movie information\n",
    "try:\n",
    "    movies = chain.invoke({\n",
    "        \"number\": 3,\n",
    "        \"topic\": \"time travel\",\n",
    "    })\n",
    "    \n",
    "    # Output the movies\n",
    "    print(movies)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
